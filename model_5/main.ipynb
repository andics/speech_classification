{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the contributions made to the original code:\n",
    " * Implemented GPU parallelism. Added a _DistributedSampler_ as an alternative to _Sampler_.\n",
    " * Wrapped the model into a _DataParallel_.\n",
    " * Made modifications to the _collatebatch_ in order to pad vectors for multi-GPU tensor processing.\n",
    " * Managed to sucesfully train on 8 NVIDIA V40.\n",
    "\n",
    "Due to the simplicity of the model, the training on multiple GPUs actually caused slower progress. The *second portion* of this notebook proceeds to train on a single GPU only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1gYr_aoNDue"
   },
   "source": [
    "# Multi-GPU training: setup of Data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cd7hoGhYtbXQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    " \n",
    "class myDataset(Dataset):\n",
    "  def __init__(self, data_dir, segment_len=128):\n",
    "    self.data_dir = data_dir\n",
    "    self.segment_len = segment_len\n",
    " \n",
    "    # Load the mapping from speaker neme to their corresponding id. \n",
    "    mapping_path = Path(data_dir) / \"mapping.json\"\n",
    "    mapping = json.load(mapping_path.open())\n",
    "    self.speaker2id = mapping[\"speaker2id\"]\n",
    " \n",
    "    # Load metadata of training data.\n",
    "    metadata_path = Path(data_dir) / \"metadata.json\"\n",
    "    metadata = json.load(open(metadata_path))[\"speakers\"]\n",
    " \n",
    "    # Get the total number of speaker.\n",
    "    self.speaker_num = len(metadata.keys())\n",
    "    self.data = []\n",
    "    for speaker in metadata.keys():\n",
    "      for utterances in metadata[speaker]:\n",
    "        self.data.append([utterances[\"feature_path\"], self.speaker2id[speaker]])\n",
    " \n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    " \n",
    "  def __getitem__(self, index):\n",
    "    feat_path, speaker = self.data[index]\n",
    "    # Load preprocessed mel-spectrogram.\n",
    "    mel = torch.load(os.path.join(self.data_dir, feat_path))\n",
    " \n",
    "    # Segmemt mel-spectrogram into \"segment_len\" frames.\n",
    "    if len(mel) > self.segment_len:\n",
    "      # Randomly get the starting point of the segment.\n",
    "      start = random.randint(0, len(mel) - self.segment_len)\n",
    "      # Get a segment with \"segment_len\" frames.\n",
    "      mel = torch.FloatTensor(mel[start:start+self.segment_len])\n",
    "    else:\n",
    "      mel = torch.FloatTensor(mel)\n",
    "    # Turn the speaker id into long for computing loss later.\n",
    "    speaker = torch.FloatTensor([speaker]).long()\n",
    "    return mel, speaker\n",
    " \n",
    "  def get_speaker_number(self):\n",
    "    return self.speaker_num\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "  # Process features within a batch.\n",
    "  \"\"\"Collate a batch of data.\"\"\"\n",
    "  mel, speaker = zip(*batch)\n",
    "  # Because we train the model batch by batch, we need to pad the features in the same batch to make their lengths the same.\n",
    "  mel = pad_sequence(mel, batch_first=True, padding_value=-20)    # pad log 10^(-20) which is very small value.\n",
    "  # mel: (batch size, length, 40)\n",
    "  return mel, torch.FloatTensor(speaker).long()\n",
    "\n",
    "\n",
    "def get_dataloader(data_dir, batch_size, n_workers):\n",
    "    dataset = myDataset(data_dir)\n",
    "    speaker_num = dataset.get_speaker_number()\n",
    "    trainlen = int(0.9 * len(dataset))\n",
    "    lengths = [trainlen, len(dataset) - trainlen]\n",
    "    trainset, validset = random_split(dataset, lengths)\n",
    "\n",
    "    train_sampler = DistributedSampler(trainset)\n",
    "    valid_sampler = DistributedSampler(validset)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        trainset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=train_sampler,\n",
    "        num_workers=n_workers,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_batch,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        validset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=valid_sampler,\n",
    "        num_workers=n_workers,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_batch,\n",
    "    )\n",
    "    return train_loader, valid_loader, speaker_num\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "  def __init__(self, d_model=80, n_spks=600, dropout=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.prenet = nn.Linear(40, d_model)\n",
    "    self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "      d_model=d_model, dim_feedforward=256, nhead=2\n",
    "    )\n",
    "    self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=3)\n",
    "\n",
    "    self.pred_layer = nn.Sequential(\n",
    "      nn.Linear(d_model, d_model),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout(dropout),\n",
    "      nn.Linear(d_model, n_spks),\n",
    "    )\n",
    "\n",
    "  def forward(self, mels):\n",
    "    out = self.prenet(mels)\n",
    "    out = out.permute(1, 0, 2)\n",
    "    out = self.encoder(out)\n",
    "    out = out.transpose(0, 1)\n",
    "    stats = out.mean(dim=1)\n",
    "\n",
    "    out = self.pred_layer(stats)\n",
    "    return out\n",
    "  \n",
    "\n",
    "def get_cosine_schedule_with_warmup(\n",
    "  optimizer: Optimizer,\n",
    "  num_warmup_steps: int,\n",
    "  num_training_steps: int,\n",
    "  num_cycles: float = 0.5,\n",
    "  last_epoch: int = -1,\n",
    "):\n",
    "  def lr_lambda(current_step):\n",
    "    # Warmup\n",
    "    if current_step < num_warmup_steps:\n",
    "      return float(current_step) / float(max(1, num_warmup_steps))\n",
    "    # decadence\n",
    "    progress = float(current_step - num_warmup_steps) / float(\n",
    "      max(1, num_training_steps - num_warmup_steps)\n",
    "    )\n",
    "    return max(\n",
    "      0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))\n",
    "    )\n",
    "\n",
    "  return LambdaLR(optimizer, lr_lambda, last_epoch)\n",
    "\n",
    "\n",
    "def model_fn(batch, model, criterion, device):\n",
    "    \"\"\"Forward a batch through the model.\"\"\"\n",
    "\n",
    "    mels, labels = batch\n",
    "    mels = mels.to(device)\n",
    "    labels = labels.to(device)\n",
    "    labels = labels.flatten()  # Flatten labels to 1D\n",
    "\n",
    "    outs = model(mels)\n",
    "\n",
    "    loss = criterion(outs, labels)\n",
    "\n",
    "    # Get the speaker id with highest probability.\n",
    "    preds = outs.argmax(1)\n",
    "    # Compute accuracy.\n",
    "    accuracy = torch.mean((preds == labels).float())\n",
    "\n",
    "    return loss, accuracy\n",
    "\n",
    "def valid(dataloader, model, criterion, device): \n",
    "  \"\"\"Validate on validation set.\"\"\"\n",
    "\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "  running_accuracy = 0.0\n",
    "  pbar = tqdm(total=len(dataloader.dataset), ncols=0, desc=\"Valid\", unit=\" uttr\")\n",
    "\n",
    "  for i, batch in enumerate(dataloader):\n",
    "    with torch.no_grad():\n",
    "      loss, accuracy = model_fn(batch, model, criterion, device)\n",
    "      running_loss += loss.item()\n",
    "      running_accuracy += accuracy.item()\n",
    "\n",
    "    pbar.update(dataloader.batch_size)\n",
    "    pbar.set_postfix(\n",
    "      loss=f\"{running_loss / (i+1):.2f}\",\n",
    "      accuracy=f\"{running_accuracy / (i+1):.2f}\",\n",
    "    )\n",
    "\n",
    "  pbar.close()\n",
    "  model.train()\n",
    "\n",
    "  return running_accuracy / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noHXyal5p1W5"
   },
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "chRQE7oYtw62",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   2% 31/2000 [00:14<15:51,  2.07 step/s, accuracy=0.24, loss=6.16, step=31]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping training: epoch is taking too long compared to single GPU (7888 > 120 sec).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"Arguments\"\"\"\n",
    "    config = {\n",
    "        \"data_dir\": \"../Dataset\",\n",
    "        \"save_path\": \"model.ckpt\",\n",
    "        \"batch_size\": 256,\n",
    "        \"n_workers\": 0,\n",
    "        \"valid_steps\": 2000,\n",
    "        \"warmup_steps\": 1000,\n",
    "        \"save_steps\": 4000,\n",
    "        \"total_steps\": 70000,\n",
    "    }\n",
    "    return config\n",
    "\n",
    "\n",
    "def main_multi_gpu(data_dir, save_path, batch_size, n_workers, valid_steps, warmup_steps, total_steps, save_steps):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    dataset = myDataset(data_dir)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, num_workers=n_workers)\n",
    "\n",
    "    model = Classifier(d_model=80, n_spks=600, dropout=0.1).to(device)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-3)\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
    "\n",
    "    best_accuracy = -1.0\n",
    "    best_state_dict = None\n",
    "\n",
    "    pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
    "    time_limit = 120  # 2 minute in seconds\n",
    "\n",
    "    for step in range(total_steps):\n",
    "        batch = next(iter(train_loader))\n",
    "        loss, accuracy = model_fn(batch, model, criterion, device)\n",
    "\n",
    "        if step == 0:\n",
    "            start_time = time.time()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        estimated_time_left = (total_steps - step) * (elapsed_time / (step+1))\n",
    "        if step>30 and estimated_time_left > time_limit:\n",
    "            print(f'Stopping training: epoch is taking too long compared to single GPU ({int(estimated_time_left)} > {time_limit} sec).')\n",
    "            return\n",
    "\n",
    "        pbar.update()\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.2f}\", accuracy=f\"{accuracy.item():.2f}\", step=step + 1)\n",
    "\n",
    "        if (step + 1) % valid_steps == 0:\n",
    "            pbar.close()\n",
    "            valid_accuracy = valid(train_loader, model, criterion, device)\n",
    "\n",
    "            if valid_accuracy > best_accuracy:\n",
    "                best_accuracy = valid_accuracy\n",
    "                best_state_dict = model.state_dict()\n",
    "                pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
    "\n",
    "        if (step + 1) % save_steps == 0 and best_state_dict:\n",
    "            torch.save(best_state_dict, save_path)\n",
    "            pbar.write(f\"Step {step + 1}, best model saved. (accuracy={best_accuracy:.4f})\")\n",
    "    pbar.close()\n",
    "\n",
    "main_multi_gpu(**parse_args())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0R2rx3AyHpQ-"
   },
   "source": [
    "# Single GPU training\n",
    "\n",
    "As no significant speedup was observed, we proceed with single GPU trianing. We redefine some important functions for single GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(data_dir, batch_size, n_workers):\n",
    "  \"\"\"Generate dataloader\"\"\"\n",
    "  dataset = myDataset(data_dir)\n",
    "  speaker_num = dataset.get_speaker_number()\n",
    "  # Split dataset into training dataset and validation dataset\n",
    "  trainlen = int(0.9 * len(dataset))\n",
    "  lengths = [trainlen, len(dataset) - trainlen]\n",
    "  trainset, validset = random_split(dataset, lengths)\n",
    "  train_loader = DataLoader(\n",
    "    trainset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=n_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_batch,\n",
    "  )\n",
    "  valid_loader = DataLoader(\n",
    "    validset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=n_workers,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_batch,\n",
    "  )\n",
    "  return train_loader, valid_loader, speaker_num\n",
    "\n",
    "def model_fn(batch, model, criterion, device):\n",
    "  \"\"\"Forward a batch through the model.\"\"\"\n",
    "\n",
    "  mels, labels = batch\n",
    "  mels = mels.to(device)\n",
    "  labels = labels.to(device)\n",
    "\n",
    "  outs = model(mels)\n",
    "\n",
    "  loss = criterion(outs, labels)\n",
    "\n",
    "  # Get the speaker id with highest probability.\n",
    "  preds = outs.argmax(1)\n",
    "  # Compute accuracy.\n",
    "  accuracy = torch.mean((preds == labels).float())\n",
    "\n",
    "  return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train:   2% 50/2000 [04:43<3:04:07,  5.67s/ step, accuracy=0.00, loss=6.42, step=50]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info]: Use cuda now!\n",
      "[Info]: Finish loading data!\n",
      "[Info]: Finish creating model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: 100% 10/10 [00:00<00:00, 21.53 step/s, accuracy=0.00, loss=6.52, step=10]\n",
      "Valid: 100% 4832/4836 [00:05<00:00, 891.04 uttr/s, accuracy=0.00, loss=6.43]\n",
      "Train: 100% 10/10 [00:00<00:00, 23.66 step/s, accuracy=0.00, loss=6.50, step=20]\n",
      "Valid: 100% 4832/4836 [00:03<00:00, 1412.66 uttr/s, accuracy=0.00, loss=6.42]\n",
      "Train: 100% 10/10 [00:00<00:00, 24.95 step/s, accuracy=0.00, loss=6.42, step=30]\n",
      "Valid:  96% 4640/4836 [00:03<00:00, 1404.36 uttr/s, accuracy=0.01, loss=6.42]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 95\u001b[0m\n\u001b[1;32m     91\u001b[0m   pbar\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m   \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 76\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(data_dir, save_path, batch_size, n_workers, valid_steps, warmup_steps, total_steps, save_steps)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m valid_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     74\u001b[0m   pbar\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m---> 76\u001b[0m   valid_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mvalid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m   \u001b[38;5;66;03m# keep the best model\u001b[39;00m\n\u001b[1;32m     79\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m valid_accuracy \u001b[38;5;241m>\u001b[39m best_accuracy:\n",
      "Cell \u001b[0;32mIn[4], line 179\u001b[0m, in \u001b[0;36mvalid\u001b[0;34m(dataloader, model, criterion, device)\u001b[0m\n\u001b[1;32m    176\u001b[0m running_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    177\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader\u001b[38;5;241m.\u001b[39mdataset), ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m uttr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m    180\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    181\u001b[0m     loss, accuracy \u001b[38;5;241m=\u001b[39m model_fn(batch, model, criterion, device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py:297\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 45\u001b[0m, in \u001b[0;36mmyDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     43\u001b[0m feat_path, speaker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index]\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Load preprocessed mel-spectrogram.\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m mel \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Segmemt mel-spectrogram into \"segment_len\" frames.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mel) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msegment_len:\n\u001b[1;32m     49\u001b[0m   \u001b[38;5;66;03m# Randomly get the starting point of the segment.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py:877\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    876\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1249\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1246\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfind_class(mod_name, name)\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;66;03m# Load the data (which may in turn use `persistent_load` to load tensors)\u001b[39;00m\n\u001b[0;32m-> 1249\u001b[0m data_file \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(\u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpickle_file\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1251\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1252\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def parse_args():\n",
    "  \"\"\"arguments\"\"\"\n",
    "  config = {\n",
    "    \"data_dir\": \"../Dataset\",\n",
    "    \"save_path\": \"model.ckpt\",\n",
    "    \"batch_size\": 32,\n",
    "    \"n_workers\": 0,\n",
    "    \"valid_steps\": 2000,\n",
    "    \"warmup_steps\": 1000,\n",
    "    \"save_steps\": 4000,\n",
    "    \"total_steps\": 70000,\n",
    "  }\n",
    "\n",
    "  return config\n",
    "\n",
    "\n",
    "def main(\n",
    "  data_dir,\n",
    "  save_path,\n",
    "  batch_size,\n",
    "  n_workers,\n",
    "  valid_steps,\n",
    "  warmup_steps,\n",
    "  total_steps,\n",
    "  save_steps,\n",
    "):\n",
    "  \"\"\"Main function.\"\"\"\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  print(f\"[Info]: Use {device} now!\")\n",
    "\n",
    "  train_loader, valid_loader, speaker_num = get_dataloader(data_dir, batch_size, n_workers)\n",
    "  train_iterator = iter(train_loader)\n",
    "  print(f\"[Info]: Finish loading data!\", flush = True)\n",
    "\n",
    "  model = Classifier(n_spks=speaker_num).to(device)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = AdamW(model.parameters(), lr=1e-3)\n",
    "  scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
    "  print(f\"[Info]: Finish creating model!\", flush = True)\n",
    "\n",
    "  best_accuracy = -1.0\n",
    "  best_state_dict = None\n",
    "\n",
    "  pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
    "\n",
    "  for step in range(total_steps):\n",
    "    # Get data\n",
    "    try:\n",
    "      batch = next(train_iterator)\n",
    "    except StopIteration:\n",
    "      train_iterator = iter(train_loader)\n",
    "      batch = next(train_iterator)\n",
    "\n",
    "    loss, accuracy = model_fn(batch, model, criterion, device)\n",
    "    batch_loss = loss.item()\n",
    "    batch_accuracy = accuracy.item()\n",
    "\n",
    "    # Updata model\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Log\n",
    "    pbar.update()\n",
    "    pbar.set_postfix(\n",
    "      loss=f\"{batch_loss:.2f}\",\n",
    "      accuracy=f\"{batch_accuracy:.2f}\",\n",
    "      step=step + 1,\n",
    "    )\n",
    "\n",
    "    # Do validation\n",
    "    if (step + 1) % valid_steps == 0:\n",
    "      pbar.close()\n",
    "\n",
    "      valid_accuracy = valid(valid_loader, model, criterion, device)\n",
    "\n",
    "      # keep the best model\n",
    "      if valid_accuracy > best_accuracy:\n",
    "        best_accuracy = valid_accuracy\n",
    "        best_state_dict = model.state_dict()\n",
    "\n",
    "      pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
    "\n",
    "    # Save the best model so far.\n",
    "    if (step + 1) % save_steps == 0 and best_state_dict is not None:\n",
    "      save_path = f\"model_{step + 1}_{best_accuracy:.4f}.ckpt\"\n",
    "      torch.save(best_state_dict, save_path)\n",
    "      pbar.write(f\"Step {step + 1}, best model saved. (accuracy={best_accuracy:.4f})\")\n",
    "\n",
    "  pbar.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main(**parse_args())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSuI3WY9Fz78"
   },
   "source": [
    "## Dataset of inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4evns0055Dsx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InferenceDataset(Dataset):\n",
    "  def __init__(self, data_dir):\n",
    "    testdata_path = Path(data_dir) / \"testdata.json\"\n",
    "    metadata = json.load(testdata_path.open())\n",
    "    self.data_dir = data_dir\n",
    "    self.data = metadata[\"utterances\"]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    utterance = self.data[index]\n",
    "    feat_path = utterance[\"feature_path\"]\n",
    "    mel = torch.load(os.path.join(self.data_dir, feat_path))\n",
    "\n",
    "    return feat_path, mel\n",
    "\n",
    "\n",
    "def inference_collate_batch(batch):\n",
    "  \"\"\"Collate a batch of data.\"\"\"\n",
    "  feat_paths, mels = zip(*batch)\n",
    "\n",
    "  return feat_paths, torch.stack(mels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oAinHBG1GIWv"
   },
   "source": [
    "## Main funcrion of Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "yQaTt7VDHoRI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info]: Use cuda now!\n",
      "[Info]: Finish loading data!\n",
      "['./model_52000_0.7163.ckpt', './model_36000_0.5676.ckpt', './model_16000_0.5178.ckpt', './model_48000_0.7061.ckpt', './model_8000_0.4392.ckpt', './model_4000_0.3148.ckpt', './model_60000_0.7305.ckpt', './model_20000_0.5799.ckpt', './model_40000_0.6861.ckpt', './model_56000_0.7305.ckpt', './model_24000_0.6010.ckpt', './model_12000_0.4998.ckpt', './model_68000_0.7417.ckpt', './model_28000_0.6231.ckpt', './model_44000_0.6968.ckpt', './model_32000_0.6527.ckpt', './model_64000_0.7394.ckpt', './model_36000_0.6571.ckpt']\n",
      "Loading from file ./model_68000_0.7417.ckpt\n",
      "[Info]: Finish creating model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                               | 0/6657 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▍                                                                                    | 33/6657 [00:00<00:20, 326.52it/s]\u001b[A\n",
      "  1%|▊                                                                                    | 66/6657 [00:00<00:20, 325.16it/s]\u001b[A\n",
      "  1%|█▎                                                                                   | 99/6657 [00:00<00:20, 327.25it/s]\u001b[A\n",
      "  2%|█▋                                                                                  | 134/6657 [00:00<00:19, 331.58it/s]\u001b[A\n",
      "  3%|██                                                                                  | 168/6657 [00:00<00:19, 330.63it/s]\u001b[A\n",
      "  3%|██▌                                                                                 | 202/6657 [00:00<00:19, 331.04it/s]\u001b[A\n",
      "  4%|██▉                                                                                 | 236/6657 [00:00<00:19, 329.75it/s]\u001b[A\n",
      "  4%|███▍                                                                                | 270/6657 [00:00<00:19, 331.72it/s]\u001b[A\n",
      "  5%|███▊                                                                                | 304/6657 [00:00<00:19, 331.68it/s]\u001b[A\n",
      "  5%|████▎                                                                               | 338/6657 [00:01<00:19, 330.75it/s]\u001b[A\n",
      "  6%|████▋                                                                               | 372/6657 [00:01<00:20, 301.71it/s]\u001b[A\n",
      "  6%|█████                                                                               | 403/6657 [00:01<00:21, 291.56it/s]\u001b[A\n",
      "  7%|█████▍                                                                              | 433/6657 [00:01<00:21, 286.28it/s]\u001b[A\n",
      "  7%|█████▊                                                                              | 462/6657 [00:01<00:21, 281.93it/s]\u001b[A\n",
      "  7%|██████▏                                                                             | 491/6657 [00:01<00:21, 282.59it/s]\u001b[A\n",
      "  8%|██████▌                                                                             | 520/6657 [00:01<00:22, 275.92it/s]\u001b[A\n",
      "  8%|██████▉                                                                             | 548/6657 [00:01<00:22, 276.80it/s]\u001b[A\n",
      "  9%|███████▎                                                                            | 577/6657 [00:01<00:21, 278.54it/s]\u001b[A\n",
      "  9%|███████▋                                                                            | 606/6657 [00:02<00:21, 279.11it/s]\u001b[A\n",
      " 10%|████████                                                                            | 634/6657 [00:02<00:21, 276.06it/s]\u001b[A\n",
      " 10%|████████▎                                                                           | 663/6657 [00:02<00:21, 278.44it/s]\u001b[A\n",
      " 10%|████████▊                                                                           | 695/6657 [00:02<00:20, 289.92it/s]\u001b[A\n",
      " 11%|█████████▏                                                                          | 725/6657 [00:02<00:20, 284.88it/s]\u001b[A\n",
      " 11%|█████████▌                                                                          | 754/6657 [00:02<00:21, 272.22it/s]\u001b[A\n",
      " 12%|█████████▊                                                                          | 782/6657 [00:02<00:21, 273.96it/s]\u001b[A\n",
      " 12%|██████████▏                                                                         | 810/6657 [00:02<00:21, 271.22it/s]\u001b[A\n",
      " 13%|██████████▌                                                                         | 839/6657 [00:02<00:21, 275.44it/s]\u001b[A\n",
      " 13%|██████████▉                                                                         | 868/6657 [00:02<00:20, 276.79it/s]\u001b[A\n",
      " 13%|███████████▎                                                                        | 896/6657 [00:03<00:21, 273.36it/s]\u001b[A\n",
      " 14%|███████████▋                                                                        | 924/6657 [00:03<00:20, 274.44it/s]\u001b[A\n",
      " 14%|████████████                                                                        | 952/6657 [00:03<00:20, 273.15it/s]\u001b[A\n",
      " 15%|████████████▎                                                                       | 980/6657 [00:03<00:20, 273.45it/s]\u001b[A\n",
      " 15%|████████████▌                                                                      | 1008/6657 [00:03<00:20, 274.25it/s]\u001b[A\n",
      " 16%|████████████▉                                                                      | 1036/6657 [00:03<00:20, 272.97it/s]\u001b[A\n",
      " 16%|█████████████▎                                                                     | 1064/6657 [00:03<00:20, 266.45it/s]\u001b[A\n",
      " 16%|█████████████▌                                                                     | 1092/6657 [00:03<00:20, 269.91it/s]\u001b[A\n",
      " 17%|█████████████▉                                                                     | 1120/6657 [00:03<00:20, 272.34it/s]\u001b[A\n",
      " 17%|██████████████▎                                                                    | 1149/6657 [00:03<00:19, 275.70it/s]\u001b[A\n",
      " 18%|██████████████▋                                                                    | 1177/6657 [00:04<00:19, 275.83it/s]\u001b[A\n",
      " 18%|███████████████                                                                    | 1206/6657 [00:04<00:19, 278.17it/s]\u001b[A\n",
      " 19%|███████████████▍                                                                   | 1234/6657 [00:04<00:19, 273.49it/s]\u001b[A\n",
      " 19%|███████████████▋                                                                   | 1262/6657 [00:04<00:19, 271.63it/s]\u001b[A\n",
      " 19%|████████████████                                                                   | 1290/6657 [00:04<00:19, 273.72it/s]\u001b[A\n",
      " 20%|████████████████▍                                                                  | 1318/6657 [00:04<00:19, 275.24it/s]\u001b[A\n",
      " 20%|████████████████▊                                                                  | 1346/6657 [00:04<00:19, 274.11it/s]\u001b[A\n",
      " 21%|█████████████████▏                                                                 | 1374/6657 [00:04<00:19, 271.36it/s]\u001b[A\n",
      " 21%|█████████████████▍                                                                 | 1402/6657 [00:04<00:19, 273.58it/s]\u001b[A\n",
      " 21%|█████████████████▊                                                                 | 1430/6657 [00:05<00:19, 273.23it/s]\u001b[A\n",
      " 22%|██████████████████▏                                                                | 1458/6657 [00:05<00:19, 272.02it/s]\u001b[A\n",
      " 22%|██████████████████▌                                                                | 1486/6657 [00:05<00:19, 271.17it/s]\u001b[A\n",
      " 23%|██████████████████▉                                                                | 1514/6657 [00:05<00:18, 272.43it/s]\u001b[A\n",
      " 23%|███████████████████▏                                                               | 1542/6657 [00:05<00:18, 274.45it/s]\u001b[A\n",
      " 24%|███████████████████▌                                                               | 1570/6657 [00:05<00:18, 272.30it/s]\u001b[A\n",
      " 24%|███████████████████▉                                                               | 1599/6657 [00:05<00:18, 275.54it/s]\u001b[A\n",
      " 24%|████████████████████▎                                                              | 1627/6657 [00:05<00:18, 273.26it/s]\u001b[A\n",
      " 25%|████████████████████▋                                                              | 1655/6657 [00:05<00:18, 272.62it/s]\u001b[A\n",
      " 25%|████████████████████▉                                                              | 1683/6657 [00:05<00:18, 271.34it/s]\u001b[A\n",
      " 26%|█████████████████████▎                                                             | 1711/6657 [00:06<00:18, 271.04it/s]\u001b[A\n",
      " 26%|█████████████████████▋                                                             | 1739/6657 [00:06<00:18, 266.87it/s]\u001b[A\n",
      " 27%|██████████████████████                                                             | 1767/6657 [00:06<00:18, 270.03it/s]\u001b[A\n",
      " 27%|██████████████████████▍                                                            | 1795/6657 [00:06<00:17, 271.52it/s]\u001b[A\n",
      " 27%|██████████████████████▋                                                            | 1823/6657 [00:06<00:17, 273.17it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████████                                                            | 1852/6657 [00:06<00:17, 275.70it/s]\u001b[A\n",
      " 28%|███████████████████████▍                                                           | 1880/6657 [00:06<00:17, 274.25it/s]\u001b[A\n",
      " 29%|███████████████████████▊                                                           | 1908/6657 [00:06<00:17, 271.18it/s]\u001b[A\n",
      " 29%|████████████████████████▏                                                          | 1938/6657 [00:06<00:17, 277.13it/s]\u001b[A\n",
      " 30%|████████████████████████▌                                                          | 1967/6657 [00:06<00:16, 278.95it/s]\u001b[A\n",
      " 30%|████████████████████████▊                                                          | 1995/6657 [00:07<00:17, 270.87it/s]\u001b[A\n",
      " 30%|█████████████████████████▏                                                         | 2023/6657 [00:07<00:17, 262.26it/s]\u001b[A\n",
      " 31%|█████████████████████████▌                                                         | 2051/6657 [00:07<00:17, 265.84it/s]\u001b[A\n",
      " 31%|█████████████████████████▉                                                         | 2080/6657 [00:07<00:16, 270.55it/s]\u001b[A\n",
      " 32%|██████████████████████████▎                                                        | 2108/6657 [00:07<00:16, 272.50it/s]\u001b[A\n",
      " 32%|██████████████████████████▋                                                        | 2137/6657 [00:07<00:16, 275.53it/s]\u001b[A\n",
      " 33%|██████████████████████████▉                                                        | 2165/6657 [00:07<00:16, 272.64it/s]\u001b[A\n",
      " 33%|███████████████████████████▎                                                       | 2193/6657 [00:07<00:16, 269.91it/s]\u001b[A\n",
      " 33%|███████████████████████████▋                                                       | 2221/6657 [00:07<00:16, 271.82it/s]\u001b[A\n",
      " 34%|████████████████████████████                                                       | 2249/6657 [00:08<00:16, 274.06it/s]\u001b[A\n",
      " 34%|████████████████████████████▍                                                      | 2277/6657 [00:08<00:16, 271.03it/s]\u001b[A\n",
      " 35%|████████████████████████████▋                                                      | 2305/6657 [00:08<00:16, 268.10it/s]\u001b[A\n",
      " 35%|█████████████████████████████                                                      | 2332/6657 [00:08<00:16, 267.79it/s]\u001b[A\n",
      " 35%|█████████████████████████████▍                                                     | 2360/6657 [00:08<00:15, 270.06it/s]\u001b[A\n",
      " 36%|█████████████████████████████▊                                                     | 2388/6657 [00:08<00:15, 272.28it/s]\u001b[A\n",
      " 36%|██████████████████████████████▏                                                    | 2417/6657 [00:08<00:15, 276.66it/s]\u001b[A\n",
      " 37%|██████████████████████████████▍                                                    | 2446/6657 [00:08<00:15, 277.97it/s]\u001b[A\n",
      " 37%|██████████████████████████████▊                                                    | 2474/6657 [00:08<00:15, 276.15it/s]\u001b[A\n",
      " 38%|███████████████████████████████▏                                                   | 2503/6657 [00:08<00:14, 278.94it/s]\u001b[A\n",
      " 38%|███████████████████████████████▌                                                   | 2533/6657 [00:09<00:14, 282.82it/s]\u001b[A\n",
      " 38%|███████████████████████████████▉                                                   | 2562/6657 [00:09<00:14, 280.24it/s]\u001b[A\n",
      " 39%|████████████████████████████████▎                                                  | 2591/6657 [00:09<00:14, 277.38it/s]\u001b[A\n",
      " 39%|████████████████████████████████▋                                                  | 2619/6657 [00:09<00:14, 276.81it/s]\u001b[A\n",
      " 40%|█████████████████████████████████                                                  | 2648/6657 [00:09<00:14, 278.80it/s]\u001b[A\n",
      " 40%|█████████████████████████████████▎                                                 | 2676/6657 [00:09<00:14, 276.84it/s]\u001b[A\n",
      " 41%|█████████████████████████████████▋                                                 | 2704/6657 [00:09<00:14, 274.25it/s]\u001b[A\n",
      " 41%|██████████████████████████████████                                                 | 2732/6657 [00:09<00:14, 272.83it/s]\u001b[A\n",
      " 41%|██████████████████████████████████▍                                                | 2760/6657 [00:09<00:14, 271.89it/s]\u001b[A\n",
      " 42%|██████████████████████████████████▊                                                | 2789/6657 [00:09<00:14, 275.08it/s]\u001b[A\n",
      " 42%|███████████████████████████████████                                                | 2817/6657 [00:10<00:13, 274.96it/s]\u001b[A\n",
      " 43%|███████████████████████████████████▍                                               | 2846/6657 [00:10<00:13, 277.17it/s]\u001b[A\n",
      " 43%|███████████████████████████████████▊                                               | 2877/6657 [00:10<00:13, 285.33it/s]\u001b[A\n",
      " 44%|████████████████████████████████████▎                                              | 2911/6657 [00:10<00:12, 298.42it/s]\u001b[A\n",
      " 44%|████████████████████████████████████▋                                              | 2944/6657 [00:10<00:12, 305.99it/s]\u001b[A\n",
      " 45%|█████████████████████████████████████▏                                             | 2978/6657 [00:10<00:11, 314.89it/s]\u001b[A\n",
      " 45%|█████████████████████████████████████▌                                             | 3011/6657 [00:10<00:11, 317.86it/s]\u001b[A\n",
      " 46%|█████████████████████████████████████▉                                             | 3043/6657 [00:10<00:11, 314.36it/s]\u001b[A\n",
      " 46%|██████████████████████████████████████▎                                            | 3076/6657 [00:10<00:11, 317.83it/s]\u001b[A\n",
      " 47%|██████████████████████████████████████▊                                            | 3108/6657 [00:11<00:11, 307.59it/s]\u001b[A\n",
      " 47%|███████████████████████████████████████▏                                           | 3140/6657 [00:11<00:11, 309.37it/s]\u001b[A\n",
      " 48%|███████████████████████████████████████▌                                           | 3173/6657 [00:11<00:11, 314.09it/s]\u001b[A\n",
      " 48%|███████████████████████████████████████▉                                           | 3206/6657 [00:11<00:10, 318.68it/s]\u001b[A\n",
      " 49%|████████████████████████████████████████▍                                          | 3239/6657 [00:11<00:10, 320.12it/s]\u001b[A\n",
      " 49%|████████████████████████████████████████▊                                          | 3272/6657 [00:11<00:10, 322.47it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████████▏                                         | 3306/6657 [00:11<00:10, 324.93it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████████▋                                         | 3339/6657 [00:11<00:10, 326.29it/s]\u001b[A\n",
      " 51%|██████████████████████████████████████████                                         | 3372/6657 [00:11<00:10, 327.16it/s]\u001b[A\n",
      " 51%|██████████████████████████████████████████▍                                        | 3405/6657 [00:11<00:09, 327.19it/s]\u001b[A\n",
      " 52%|██████████████████████████████████████████▉                                        | 3439/6657 [00:12<00:09, 329.30it/s]\u001b[A\n",
      " 52%|███████████████████████████████████████████▎                                       | 3472/6657 [00:12<00:09, 322.81it/s]\u001b[A\n",
      " 53%|███████████████████████████████████████████▋                                       | 3505/6657 [00:12<00:09, 323.42it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████████▏                                      | 3540/6657 [00:12<00:09, 329.56it/s]\u001b[A\n",
      " 54%|████████████████████████████████████████████▌                                      | 3573/6657 [00:12<00:09, 328.64it/s]\u001b[A\n",
      " 54%|████████████████████████████████████████████▉                                      | 3607/6657 [00:12<00:09, 331.03it/s]\u001b[A\n",
      " 55%|█████████████████████████████████████████████▍                                     | 3641/6657 [00:12<00:09, 330.94it/s]\u001b[A\n",
      " 55%|█████████████████████████████████████████████▊                                     | 3676/6657 [00:12<00:08, 334.10it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████████▎                                    | 3710/6657 [00:12<00:08, 334.99it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████████▋                                    | 3744/6657 [00:12<00:08, 333.94it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|███████████████████████████████████████████████                                    | 3778/6657 [00:13<00:09, 314.90it/s]\u001b[A\n",
      " 57%|███████████████████████████████████████████████▌                                   | 3810/6657 [00:13<00:09, 295.18it/s]\u001b[A\n",
      " 58%|███████████████████████████████████████████████▉                                   | 3840/6657 [00:13<00:09, 287.32it/s]\u001b[A\n",
      " 58%|████████████████████████████████████████████████▎                                  | 3874/6657 [00:13<00:09, 301.65it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████████▋                                  | 3907/6657 [00:13<00:08, 308.35it/s]\u001b[A\n",
      " 59%|█████████████████████████████████████████████████                                  | 3940/6657 [00:13<00:08, 312.14it/s]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████▌                                 | 3974/6657 [00:13<00:08, 318.68it/s]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████▉                                 | 4007/6657 [00:13<00:08, 318.91it/s]\u001b[A\n",
      " 61%|██████████████████████████████████████████████████▍                                | 4042/6657 [00:13<00:07, 327.70it/s]\u001b[A\n",
      " 61%|██████████████████████████████████████████████████▊                                | 4077/6657 [00:14<00:07, 332.52it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████████▎                               | 4111/6657 [00:14<00:07, 331.32it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████████▋                               | 4146/6657 [00:14<00:07, 334.83it/s]\u001b[A\n",
      " 63%|████████████████████████████████████████████████████▏                              | 4181/6657 [00:14<00:07, 337.59it/s]\u001b[A\n",
      " 63%|████████████████████████████████████████████████████▌                              | 4215/6657 [00:14<00:07, 336.97it/s]\u001b[A\n",
      " 64%|████████████████████████████████████████████████████▉                              | 4250/6657 [00:14<00:07, 339.81it/s]\u001b[A\n",
      " 64%|█████████████████████████████████████████████████████▍                             | 4284/6657 [00:14<00:06, 339.51it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████████▊                             | 4318/6657 [00:14<00:06, 339.31it/s]\u001b[A\n",
      " 65%|██████████████████████████████████████████████████████▎                            | 4353/6657 [00:14<00:06, 341.21it/s]\u001b[A\n",
      " 66%|██████████████████████████████████████████████████████▋                            | 4388/6657 [00:14<00:06, 336.21it/s]\u001b[A\n",
      " 66%|███████████████████████████████████████████████████████▏                           | 4422/6657 [00:15<00:06, 334.21it/s]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████▌                           | 4456/6657 [00:15<00:06, 333.49it/s]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████▉                           | 4491/6657 [00:15<00:06, 337.05it/s]\u001b[A\n",
      " 68%|████████████████████████████████████████████████████████▍                          | 4526/6657 [00:15<00:06, 339.55it/s]\u001b[A\n",
      " 69%|████████████████████████████████████████████████████████▊                          | 4561/6657 [00:15<00:06, 340.65it/s]\u001b[A\n",
      " 69%|█████████████████████████████████████████████████████████▎                         | 4596/6657 [00:15<00:06, 333.43it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████▋                         | 4630/6657 [00:15<00:06, 330.23it/s]\u001b[A\n",
      " 70%|██████████████████████████████████████████████████████████▏                        | 4664/6657 [00:15<00:06, 328.00it/s]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████████████▌                        | 4697/6657 [00:15<00:05, 327.94it/s]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████████████▉                        | 4730/6657 [00:15<00:05, 325.20it/s]\u001b[A\n",
      " 72%|███████████████████████████████████████████████████████████▍                       | 4763/6657 [00:16<00:05, 321.89it/s]\u001b[A\n",
      " 72%|███████████████████████████████████████████████████████████▊                       | 4796/6657 [00:16<00:05, 320.65it/s]\u001b[A\n",
      " 73%|████████████████████████████████████████████████████████████▏                      | 4829/6657 [00:16<00:05, 322.76it/s]\u001b[A\n",
      " 73%|████████████████████████████████████████████████████████████▋                      | 4864/6657 [00:16<00:05, 330.76it/s]\u001b[A\n",
      " 74%|█████████████████████████████████████████████████████████████                      | 4898/6657 [00:16<00:05, 331.83it/s]\u001b[A\n",
      " 74%|█████████████████████████████████████████████████████████████▍                     | 4932/6657 [00:16<00:05, 334.07it/s]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████████████▉                     | 4966/6657 [00:16<00:05, 333.14it/s]\u001b[A\n",
      " 75%|██████████████████████████████████████████████████████████████▎                    | 5000/6657 [00:16<00:04, 333.98it/s]\u001b[A\n",
      " 76%|██████████████████████████████████████████████████████████████▊                    | 5034/6657 [00:16<00:04, 333.43it/s]\u001b[A\n",
      " 76%|███████████████████████████████████████████████████████████████▏                   | 5068/6657 [00:17<00:04, 330.90it/s]\u001b[A\n",
      " 77%|███████████████████████████████████████████████████████████████▌                   | 5102/6657 [00:17<00:04, 322.47it/s]\u001b[A\n",
      " 77%|████████████████████████████████████████████████████████████████                   | 5136/6657 [00:17<00:04, 326.26it/s]\u001b[A\n",
      " 78%|████████████████████████████████████████████████████████████████▍                  | 5169/6657 [00:17<00:04, 327.15it/s]\u001b[A\n",
      " 78%|████████████████████████████████████████████████████████████████▉                  | 5204/6657 [00:17<00:04, 331.83it/s]\u001b[A\n",
      " 79%|█████████████████████████████████████████████████████████████████▎                 | 5238/6657 [00:17<00:04, 330.74it/s]\u001b[A\n",
      " 79%|█████████████████████████████████████████████████████████████████▋                 | 5272/6657 [00:17<00:04, 330.91it/s]\u001b[A\n",
      " 80%|██████████████████████████████████████████████████████████████████▏                | 5306/6657 [00:17<00:04, 330.21it/s]\u001b[A\n",
      " 80%|██████████████████████████████████████████████████████████████████▌                | 5340/6657 [00:17<00:04, 323.60it/s]\u001b[A\n",
      " 81%|███████████████████████████████████████████████████████████████████                | 5374/6657 [00:17<00:03, 327.91it/s]\u001b[A\n",
      " 81%|███████████████████████████████████████████████████████████████████▍               | 5407/6657 [00:18<00:03, 326.28it/s]\u001b[A\n",
      " 82%|███████████████████████████████████████████████████████████████████▊               | 5441/6657 [00:18<00:03, 327.71it/s]\u001b[A\n",
      " 82%|████████████████████████████████████████████████████████████████████▎              | 5474/6657 [00:18<00:03, 326.54it/s]\u001b[A\n",
      " 83%|████████████████████████████████████████████████████████████████████▋              | 5508/6657 [00:18<00:03, 328.72it/s]\u001b[A\n",
      " 83%|█████████████████████████████████████████████████████████████████████              | 5541/6657 [00:18<00:03, 329.06it/s]\u001b[A\n",
      " 84%|█████████████████████████████████████████████████████████████████████▌             | 5575/6657 [00:18<00:03, 329.86it/s]\u001b[A\n",
      " 84%|█████████████████████████████████████████████████████████████████████▉             | 5608/6657 [00:18<00:03, 324.59it/s]\u001b[A\n",
      " 85%|██████████████████████████████████████████████████████████████████████▎            | 5641/6657 [00:18<00:03, 325.20it/s]\u001b[A\n",
      " 85%|██████████████████████████████████████████████████████████████████████▋            | 5674/6657 [00:18<00:03, 321.89it/s]\u001b[A\n",
      " 86%|███████████████████████████████████████████████████████████████████████▏           | 5707/6657 [00:18<00:02, 320.57it/s]\u001b[A\n",
      " 86%|███████████████████████████████████████████████████████████████████████▌           | 5740/6657 [00:19<00:03, 285.71it/s]\u001b[A\n",
      " 87%|███████████████████████████████████████████████████████████████████████▉           | 5773/6657 [00:19<00:02, 297.63it/s]\u001b[A\n",
      " 87%|████████████████████████████████████████████████████████████████████████▍          | 5808/6657 [00:19<00:02, 310.91it/s]\u001b[A\n",
      " 88%|████████████████████████████████████████████████████████████████████████▊          | 5842/6657 [00:19<00:02, 318.52it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████████████████████████████████████████▎         | 5876/6657 [00:19<00:02, 322.36it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|█████████████████████████████████████████████████████████████████████████▋         | 5909/6657 [00:19<00:02, 321.92it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████████████████████████████████████████         | 5943/6657 [00:19<00:02, 324.72it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████████████████████████████████████████▌        | 5976/6657 [00:19<00:02, 321.05it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████████████████████████████████████████▉        | 6010/6657 [00:19<00:02, 323.41it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████████████████████████████████████████▎       | 6044/6657 [00:20<00:01, 326.96it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████████████████████████████████████████▊       | 6077/6657 [00:20<00:01, 326.39it/s]\u001b[A\n",
      " 92%|████████████████████████████████████████████████████████████████████████████▏      | 6110/6657 [00:20<00:01, 326.63it/s]\u001b[A\n",
      " 92%|████████████████████████████████████████████████████████████████████████████▌      | 6144/6657 [00:20<00:01, 328.68it/s]\u001b[A\n",
      " 93%|█████████████████████████████████████████████████████████████████████████████      | 6180/6657 [00:20<00:01, 335.21it/s]\u001b[A\n",
      " 93%|█████████████████████████████████████████████████████████████████████████████▍     | 6214/6657 [00:20<00:01, 335.37it/s]\u001b[A\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████▉     | 6248/6657 [00:20<00:01, 333.28it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████████████████████████████████████████████▎    | 6282/6657 [00:20<00:01, 330.68it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████████████████████████████████████████████▋    | 6316/6657 [00:20<00:01, 330.48it/s]\u001b[A\n",
      " 95%|███████████████████████████████████████████████████████████████████████████████▏   | 6350/6657 [00:20<00:00, 327.99it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████████████████████████████████████████████▌   | 6383/6657 [00:21<00:00, 328.24it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████████████████████████████████████████████▉   | 6416/6657 [00:21<00:00, 328.16it/s]\u001b[A\n",
      " 97%|████████████████████████████████████████████████████████████████████████████████▍  | 6450/6657 [00:21<00:00, 331.54it/s]\u001b[A\n",
      " 97%|████████████████████████████████████████████████████████████████████████████████▊  | 6484/6657 [00:21<00:00, 326.11it/s]\u001b[A\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████████▎ | 6519/6657 [00:21<00:00, 331.75it/s]\u001b[A\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████████▋ | 6554/6657 [00:21<00:00, 335.60it/s]\u001b[A\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████████▏| 6588/6657 [00:21<00:00, 330.18it/s]\u001b[A\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████████▌| 6622/6657 [00:21<00:00, 326.36it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 6657/6657 [00:21<00:00, 304.11it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def parse_args():\n",
    "  \"\"\"arguments\"\"\"\n",
    "  config = {\n",
    "    \"data_dir\": \"../Dataset\",\n",
    "    \"model_path\": \"./model.ckpt\",\n",
    "    \"output_path\": \"./output.csv\",\n",
    "  }\n",
    "\n",
    "  return config\n",
    "\n",
    "\n",
    "def main(\n",
    "  data_dir,\n",
    "  model_path,\n",
    "  output_path,\n",
    "):\n",
    "  \"\"\"Main function.\"\"\"\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  print(f\"[Info]: Use {device} now!\")\n",
    "\n",
    "  mapping_path = Path(data_dir) / \"mapping.json\"\n",
    "  mapping = json.load(mapping_path.open())\n",
    "\n",
    "  dataset = InferenceDataset(data_dir)\n",
    "  dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=inference_collate_batch,\n",
    "  )\n",
    "  print(f\"[Info]: Finish loading data!\",flush = True)\n",
    "\n",
    "  speaker_num = len(mapping[\"id2speaker\"])\n",
    "  model = Classifier(n_spks=speaker_num).to(device)\n",
    "  # new code to automatically find and load the best model\n",
    "  list_of_files = glob.glob(f\"./*.ckpt\")  # get list of all model files\n",
    "  print(list_of_files)\n",
    "  latest_file = max(list_of_files, key=lambda x: float(x.split('_')[2].split('.')[1]))  # get the best model file\n",
    "  print(f\"Loading from file {latest_file}\")\n",
    "  model.load_state_dict(torch.load(latest_file))\n",
    "  model.eval()\n",
    "  print(f\"[Info]: Finish creating model!\",flush = True)\n",
    "\n",
    "  results = [[\"Id\", \"Category\"]]\n",
    "  for feat_paths, mels in tqdm(dataloader):\n",
    "    with torch.no_grad():\n",
    "      mels = mels.to(device)\n",
    "      outs = model(mels)\n",
    "      preds = outs.argmax(1).cpu().numpy()\n",
    "      for feat_path, pred in zip(feat_paths, preds):\n",
    "        results.append([feat_path, mapping[\"id2speaker\"][str(pred)]])\n",
    "  \n",
    "  with open(output_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(results)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main(**parse_args())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW04 (1).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
